{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83e\udde0 1.0 \u2014 Reinforcement Learning: Review & Practice\n", "**Module:** B9AI105 \u2014 Reinforcement Learning  \n", "**Instructor:** Dr. Basel Magableh  \n", "**Purpose:** Reinforce RL theory and practice with Gymnasium environments"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udcd8 Part 1 \u2014 Concept Review (Written Questions)\n", "**Q1.** What is the main difference between Reinforcement Learning and Supervised Learning?\n\n", "**Q2.** Define the following terms:\n", "- Agent\n", "- Environment\n", "- State\n", "- Action\n", "- Reward\n\n", "**Q3.** What is a Markov Decision Process (MDP)? Name its key components.\n\n", "**Q4.** What is a policy in RL? Differentiate between:\n", "- Deterministic Policy\n", "- Stochastic Policy\n\n", "**Q5.** What is an episode in RL?\n\n", "**Q6.** Define:\n", "- Value Function\n", "- Q-Function\n", "How do they differ?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\udde0 Part 2 \u2014 Check Your Understanding (Multiple Choice)\n", "**Q7.** Which of the following best describes the Markov Property?\n", "a) The past and future are equally important  \n", "b) The current state depends on the entire past history  \n", "c) The next state depends only on the current state and action  \n", "d) The reward is always positive\n\n", "**Q8.** In which type of environment does the same action in a state always lead to the same next state?\n", "a) Stochastic  \n", "b) Deterministic  \n", "c) Episodic  \n", "d) Continuous"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udd01 Part 3 \u2014 Agent-Environment Loop (Gymnasium)\n", "import gymnasium as gym\n", "\n", "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n", "observation, info = env.reset()\n", "\n", "done = False\n", "while not done:\n", "    action = env.action_space.sample()\n", "    observation, reward, terminated, truncated, info = env.step(action)\n", "    done = terminated or truncated\n", "\n", "env.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\ude80 Part 4 \u2014 LunarLander-v2: Basic Exploration\n", "**Task:** Run the agent using random actions and observe the result. What is the reward trend like?\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n", "observation, info = env.reset()\n", "\n", "done = False\n", "total_reward = 0\n", "while not done:\n", "    action = env.action_space.sample()\n", "    observation, reward, terminated, truncated, info = env.step(action)\n", "    total_reward += reward\n", "    done = terminated or truncated\n", "\n", "print(\"Total Reward:\", total_reward)\n", "env.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83c\udfd4 Part 5 \u2014 MountainCar-v0: Reaching the Flag\n", "**Task:** Try multiple runs and observe why the agent struggles to reach the goal. What needs to change?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["env = gym.make(\"MountainCar-v0\", render_mode=\"human\")\n", "observation, info = env.reset()\n", "\n", "done = False\n", "while not done:\n", "    action = env.action_space.sample()\n", "    observation, reward, terminated, truncated, info = env.step(action)\n", "    done = terminated or truncated\n", "\n", "env.close()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 5}